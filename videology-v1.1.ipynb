{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries / dependencies\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook, Workbook\n",
    "import csv\n",
    "from pyexcel.cookbook import merge_all_to_a_book, merge_csv_to_a_book\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS BLOCK\n",
    "\n",
    "#get_filenames: \n",
    "#Arguments: raw data filepath (absolute)\n",
    "#Returns: A tuple of strings representing the files that will be used to \n",
    "#represent the data at each step of refinement\n",
    "def get_filenames(rdfile):\n",
    "    #EXAMPLE '/Users/default/Downloads/Videology Reports/TruOptik - Monthly Usage - June 2018.xlsx'\n",
    "    rd = rdfile.split('/')\n",
    "    path = '/'.join(rd[:-1])\n",
    "    extractedfile = path+'/Extracted-'+rd[-1][:-4]+'csv'\n",
    "    correctedfile = path+'/Corrected-'+rd[-1][:-4]+'csv'\n",
    "    finalfile = path+'/Final-'+rd[-1]\n",
    "    correctedfile_excel = path+'/Corrected-'+rd[-1]\n",
    "    return extractedfile, correctedfile, finalfile, correctedfile_excel\n",
    "\n",
    "#replacements:\n",
    "#Argument: the videology category (string)\n",
    "#Returns: the category with all necessary corrections (string)\n",
    "#Basically there are duplicates in the categories that are *slightly* different\n",
    "#and this takes care of those. it's pretty ugly but I haven't thought of a better way yet\n",
    "def replacements(category):\n",
    "    category = category.replace('Financial','Financial/Insurance Attributes & Behaviors')\n",
    "    category = category.replace('Financial/Insurance Attributes & Behaviors/Insurance Attributes & Behaviors','Financial/Insurance Attributes & Behaviors')\n",
    "    category = category.replace('\"','')\n",
    "    category = category.replace('Home & Garden','Home Imp/Décor/Home & Garden/Home&Fam/DIY').replace('Home Imp/Décor/Home Imp/Décor/Home & Garden/Home&Fam/DIY/Home&Fam/DIY','Home Imp/Décor/Home & Garden/Home&Fam/DIY')\n",
    "    category = category.replace('Demos','Demo')\n",
    "    category = category.replace('Sports & Outdoors','Sporting & Healthy Living + Sporting Goods/Outdoor')\n",
    "    category = category.replace('Education/Career','Education & Career')\n",
    "    category = category.replace('Entertainment/Media','Entertainment & Media')\n",
    "    category = category.replace('Fashion & Style', 'Fashion/Style; Apparel; Accessories')\n",
    "    category = category.replace('Health','Health & Fitness/Wellness').replace('Health & Fitness/Wellness & Fitness/Wellness','Health & Fitness/Wellness')\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Provider', 'Country', 'Retargeting Attribute', 'Attribute ID', 'Device Type', 'Format Type', 'CPU', 'Usage', 'Data Costs', 'Rate Adjustment', 'Adjusted Cost (PC/Mobile)']\n",
      "[2, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "#BLOCK 1: EXTRACT THE ATTRIBUTES, IDS, AND USAGE DATA FROM THE EXCEL SHEET and get unique values. Then store in CSV\n",
    "\n",
    "#absolute filepath to raw_data (Videology Report)\n",
    "raw_data = '/Users/default/Downloads/Videology Reports/filedump/TruOptik - Monthly Usage - April 2018.xlsx'\n",
    "\n",
    "#This program will create the edited files in the same location as the original, so look there for the data\n",
    "extractedfile, correctedfile, finalfile, correctedfile_excel = get_filenames(raw_data)\n",
    "\n",
    "#use openpyxl library to create a workbook object from the xlsx file so we can work w it\n",
    "rd_wb = load_workbook(raw_data)\n",
    "\n",
    "#get the worksheet with the data\n",
    "#usually the sheet is named 'Behavioral Cost', but sometimes there is a trailing space or its named something else\n",
    "#because Videology is allergic to consistency. Either way changing the string will get you the desired worksheet\n",
    "rd_ws = rd_wb['Behavioral Cost']\n",
    "\n",
    "#the header has the names for each column in the worksheet\n",
    "header = [x.value for x in list(rd_ws.rows)[0]]\n",
    "print(header)\n",
    "\n",
    "#we want the index of the columns for the following: \n",
    "#Retargeting Attribute\n",
    "#Attribute ID (sometimes called External Retargeting ID so just change string)\n",
    "#Usage (sometimes called Billable Usage)\n",
    "ra_ind = header.index('Retargeting Attribute')\n",
    "erid_ind= header.index('Attribute ID')\n",
    "usage_ind = header.index('Usage')\n",
    "\n",
    "print([ra_ind, erid_ind, usage_ind])\n",
    "\n",
    "#The following block of code creates a dictionary of unique attributes\n",
    "#Dictionary format is \"unique_records[attribute] = usage\"\n",
    "\n",
    "unique_records = {}\n",
    "for item in [[i.value for i in x] for x in rd_ws.iter_rows(min_row=2)]:\n",
    "    #edit the row if it exists\n",
    "    if item[ra_ind] is not None: \n",
    "        row = [item[ra_ind].replace(',',';').replace('  ',' '),item[erid_ind],item[usage_ind]]\n",
    "    else:\n",
    "        pass\n",
    "    #check for membership in the dictionary keys\n",
    "    if row[0] in list(unique_records.keys()):\n",
    "        #if the usage value is an int, add it to the dictionary (this gets rid of excel formulas)\n",
    "        if isinstance(item[usage_ind],int):\n",
    "            unique_records[row[0]] += int(item[usage_ind])\n",
    "    #otherwise create new entry\n",
    "    elif row[0] not in list(unique_records.keys()):\n",
    "        if isinstance(item[usage_ind],int):\n",
    "            unique_records[row[0]] = int(item[usage_ind])\n",
    "\n",
    "#write this unique record data to a csv\n",
    "extracted_data = open(extractedfile,'w')\n",
    "for kv in unique_records.items():\n",
    "    write = csv.writer(extracted_data)\n",
    "    write.writerow(kv)\n",
    "extracted_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BLOCK 1A: IF THE DATA ISN'T IN A FRIENDLY FORMAT IN THE RAW DATA, INSTEAD USE A SLIGHTLY EDITED VERSION AND CONTINUE FROM THERE\n",
    "#This block was written because in 1 videology report they had the attribute separated into multiple columns instead of their\n",
    "#normal format\n",
    "refined_data = '/Users/default/Documents/PythonMisc/Videology Reports - Completed/Edited - Dec2017Categories copy.xlsx'\n",
    "wb = load_workbook(refined_data)\n",
    "ws = wb.active\n",
    "category_dict = {}\n",
    "for line in [[i.value for i in x] for x in ws.iter_rows()]:\n",
    "    if line[1].strip() in list(category_dict.keys()):\n",
    "        category_dict[line[1].strip()] += int(line[2])\n",
    "    else:\n",
    "        category_dict[line[1].strip()] = int(line[2])\n",
    "for key, value in category_dict.items():\n",
    "    index = list(category_dict.keys()).index(key) + 1\n",
    "    ws.cell(row = index, column = 4).value = key\n",
    "    ws.cell(row = index, column = 5).value = value\n",
    "wb.save(refined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1410\n"
     ]
    }
   ],
   "source": [
    "#BLOCK 2: CATEGORIZE THE UNIQUE VALUES USING PREVIOUS DATA\n",
    "#load reference file and create a list of lists of its values\n",
    "\n",
    "#this block loads an excel file and creates a dictionary in the form: dict[attribute] = category\n",
    "#with this dictionary we take care of a lot of repeated values so recategorization is easier \n",
    "#some new attributes won't be in the database so they might be blank but i'm working on fixing that with another method\n",
    "db_path = '/Users/default/Documents/PythonMisc/VideologyDatabase.xlsx'\n",
    "db_file = load_workbook(db_path)\n",
    "db_ws = db_file.active\n",
    "db_contents = {}\n",
    "for attribute, category in [[i.value for i in x] for x in db_ws.iter_rows(max_col=2)]:\n",
    "    db_contents[attribute] = category\n",
    "    \n",
    "print(len(db_contents))\n",
    "\n",
    "#load file with missing categories and create list of values\n",
    "edit_file = open(extractedfile,'r')\n",
    "corrected_vals = []\n",
    "for line in edit_file:\n",
    "    #preprocessing the line\n",
    "    edited_line = line.replace('\"','').strip().split(',',1)\n",
    "    attribute = edited_line[0]\n",
    "    usage = edited_line[1]\n",
    "    #add to corrected values if it is in the database otherwise leave it blank\n",
    "    try:\n",
    "        corrected_vals.append([attribute,db_contents[attribute], usage]) \n",
    "    except KeyError:\n",
    "        corrected_vals.append([attribute,'',usage])\n",
    "        \n",
    "#write to another file\n",
    "corrected_file = open(correctedfile,'w')\n",
    "for value in corrected_vals:\n",
    "    write = csv.writer(corrected_file)\n",
    "    write.writerow(value)\n",
    "corrected_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/default/anaconda/lib/python3.6/site-packages/openpyxl/workbook/child.py:102: UserWarning: Title is more than 31 characters. Some applications may not be able to read the file\n",
      "  warnings.warn(\"Title is more than 31 characters. Some applications may not be able to read the file\")\n"
     ]
    }
   ],
   "source": [
    "#BLOCK 3: CREATE DICTIONARY BASED ON UNIQUE CATEGORIES AND WRITE TO XL FILE\n",
    "#ONLY RUN THIS BLOCK AFTER EDITS HAVE BEEN MADE TO CSV CREATED IN PREVIOUS BLOCK\n",
    "\n",
    "#convert corrected csv to excel file so we can write into it\n",
    "merge_csv_to_a_book([correctedfile],correctedfile_excel)\n",
    "\n",
    "\n",
    "#create dictionary\n",
    "category_dict = {}\n",
    "corrected_csv = open(correctedfile)\n",
    "for line in corrected_csv:\n",
    "    #more preprocessing\n",
    "    line = line.replace('\"\"\"Fashion/Style, Apparel, Accessories\"\"\"', ',Fashion/Style; Apparel; Accessories').replace(',,',',').strip()\n",
    "    #Some categories have commas which fuck up reading the csv so i replaced them w semicolons\n",
    "    if len(line.split(',')) > 3:\n",
    "        line = line.replace('Style,','Style;').replace('Apparel,','Apparel;')\n",
    "    line = line.split(',')\n",
    "    \n",
    "    attribute,category = line[:2]\n",
    "    usage=int(line[2])\n",
    "    category = replacements(category)\n",
    "    \n",
    "    #same dictionary logic as before (should probably be a fcn)\n",
    "    if category in list(category_dict.keys()):\n",
    "        category_dict[category] += usage\n",
    "    elif category not in list(category_dict.keys()):\n",
    "        category_dict[category] = usage\n",
    "\n",
    "#now write to an excel file with the dictionary\n",
    "wb = load_workbook(correctedfile_excel)\n",
    "ws = wb.active\n",
    "for key, value in category_dict.items():\n",
    "    index = list(category_dict.keys()).index(key)+1\n",
    "    ws.cell(row = index, column = 6).value = key\n",
    "    ws.cell(row = index, column = 7).value = value\n",
    "\n",
    "wb.save(finalfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pattern' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-82dab72968d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolder_contents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pattern' is not defined"
     ]
    }
   ],
   "source": [
    "#SIDE PROJECT: CREATE A DATABASE OF VALUES THAT HAVE CORRECT LABELS\n",
    "#RUN ONLY ONCE: THIS WILL OVERWRITE THE CURRENT DATABASE\n",
    "folder_path = '/Users/default/Documents/PythonMisc/Videology Reports - Completed'\n",
    "folder_contents = os.listdir(folder_path)\n",
    "\n",
    "db_path = '/Users/default/Documents/PythonMisc/VideologyDatabase.xlsx'\n",
    "db_file = load_workbook(db_path)\n",
    "db_ws = db_file.active\n",
    "db_contents = {}\n",
    "pattern = '^[Ee]'\n",
    "\n",
    "print(len(db_contents))\n",
    "for attribute, category in [[i.value for i in x] for x in db_ws.iter_rows(max_col=2)]:\n",
    "    db_contents[attribute] = category\n",
    "\n",
    "for file in folder_contents:\n",
    "    if re.match(pattern, file):\n",
    "        wb = load_workbook(folder_path + '/' + file)\n",
    "        ws = wb.active\n",
    "\n",
    "        #only want the first 2 columns (attribute and category)\n",
    "        for attribute, category in [[i.value for i in x] for x in ws.iter_rows(max_col=2)]:\n",
    "            if attribute is None:\n",
    "                attribute = 'TEST'\n",
    "                category = 'TEST'\n",
    "            if '>' == attribute[-1]:\n",
    "                attribute = attribute[:-2]\n",
    "            try:\n",
    "                category = replacements(category)\n",
    "            except:\n",
    "                print('no bueno')\n",
    "            db_contents[attribute] = category\n",
    "\n",
    "print(len(db_contents))\n",
    "\n",
    "#Now, we write the completed dictionary to the database file again\n",
    "for i, (key, value) in enumerate(db_contents.items()):\n",
    "    db_ws.cell(row=i+1, column = 1).value = key\n",
    "    db_ws.cell(row=i+1, column = 2).value = value\n",
    "    \n",
    "db_file.save(db_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
